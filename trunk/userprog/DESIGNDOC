                        +--------------------------+
                        |          CS 140          |
                        | PROJECT 2: USER PROGRAMS |
                        |      DESIGN DOCUMENT     |
                        +--------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Josh Parnell <parnell@stanford.edu>
Steve Lesser <sklesser@stanford.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

   	 	    ARGUMENT PASSING
		    ================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

No changes required for argument passing.

---- ALGORITHMS ----

>> A2: Briefly describe how you implemented argument parsing.  How do
>> you arrange for the elements of argv[] to be in the right order?
>> How do you avoid overflowing the stack page?

In the original system, process_execute allocated a page of memory
and copied the filename to that page to pass it to the newly-executed
process. We use the same page to pass the arguments to the new process.
In start_process, we call start_process_parse_args, which sets up the
stack.

start_process_parse_args works by making an initial pass over the
arguments, calculating how many arguments exist and how much
whitespace there is. Using this information, we can then compute
the exact amount of memory required for the string data of argv
as well as the pointers of argv. Hance, at this point, we compute
how much total stack space we'll need. If it exceeds a page, we
return false and start_process reports failure. In this way, we
prevent overflow of the stack page.

After verifying that the memory requirements are reasonable, the
function copies all of the string data onto the stack in order
of appearance, while simultaneously wiring up the argv pointers
to the string data that is being written. This is only possible
because we pre-computed the memory requirements, so we know
exactly where everything should be on the stack. Furthermore, we
can process the arguments in-order such that argv reflects the
expected order.

Note that we do the actual argument parsing in start_process, not
process_execute.

---- RATIONALE ----

>> A3: Why does Pintos implement strtok_r() but not strtok()?

The C-standard strtok makes use of a static pointer to keep track of
its location within the string that it is currently parsing. This is
a terrible approach, because it yields undefined and potentially
disastrous behavior if a parent function is in the middle of running
strtok when it calls a child function. If the child function uses
strtok, the parent's strtok will lose track of the pointer and will
yield unwanted results.

If strtok is to be used safely, we have to know with certainty that
anything we call while using strtok will not also try to use strtok.
This is a terrible limitation and danger. In any reasonable system,
we would expect to have to keep track of our own position pointer
rather than letting a static pointer do so, which is precisely what
strtok_r does. strtok_r is safe to use even if calls to other functions
are made during use, since we are responsible for keeping track of
the memory used to store the position pointer, hence, strtok_r is
reentrant, unlike strtok.

>> A4: In Pintos, the kernel separates commands into a executable name
>> and arguments.  In Unix-like systems, the shell does this
>> separation.  Identify at least two advantages of the Unix approach.

First, the Unix approach is safer. Having the Kernel do less work means
less opportunity to make a mistake that could potentially lead to a
bug or, worse, a security vulnerability in the host machine. Having a
process such as the shell do this work is safer: assuming the OS has
measures in place to make user processes "safe," then it need not worry
about vulnerabilities in argument passing, since this will be done by
the shell.

Second, the Unix approach is flexible - different shells can choose to
interpret and parse arguments in different ways, which could be useful
depending on how the user wishes to communicate with programs, or, more
importantly, how programs wish to communicate with one another. Having
the kernel perform this separation would lead to either more code
paths in the kernel to support different argument-passing methods (bad
idea, more code in kernel -> more security vulnerabilities), or no
ability to support other argument-passing schemes (inflexible).

   			      SYSTEM CALLS
			      ============

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

------------ syscall.c ---------------

/* Split calls to putbuf up into chunks of PUTBUF_BLOCK_SIZE
   bytes each. */
#define PUTBUF_BLOCK_SIZE 128

static struct lock filesys_lock;    /* Lock for file system access. */
static struct hash filesys_fdhash;  /* Hash table mapping fds to
                                       struct file*s. */
static struct hash filesys_fileref; /* Hash table for counting number of
                                       open handles to a file and
                                       whether it's been marked for
                                       deletion. */

/* Gives the number of arguments expected for a given system
   call number. Useful to unify the argument-parsing code in
   syscall_handler. */
static uint8_t syscall_arg_count[] =
{
  0,      /* Halt */
  1,      /* Exit */
  1,      /* Exec */
  1,      /* Wait */
  2,      /* Create */
  1,      /* Remove */
  1,      /* Open */
  1,      /* FileSize */
  3,      /* Read */
  3,      /* Write */
  2,      /* Seek */
  1,      /* Tell */
  1       /* Close */
};

/* An fd_elem encapsulates the information held by a file descriptor.
   The fd_elem is inserted into the filesys_fdhash table upon creation
   of the fd, and is used to keep track of file information. The fd_elem
   is also attached to the creating thread's open_files list. This is
   the central element for file resource tracking. */
struct fd_elem
{
  struct hash_elem h_elem;          /* Element hash table insertion. */
  struct list_elem l_elem;          /* Element for list insertion. */
  int fd;                           /* Associated fd number. */
  int owner_pid;                    /* pid of the owning process. */
  struct file *file;                /* File system file handle. */
};

/* A fileref_elem encapsulates information about a particular file's
   reference count - that is, how many outstanding FDs reference
   the file. It also indicates whether the file is marked for deletion
   or not. */
struct fileref_elem
{
  struct hash_elem h_elem;          /* Element hash table insertion. */
  int inumber;                      /* inode number specifying the
                                       file. */
  int count;                        /* Number of existing references to
                                       this file. */
  bool delete;                      /* Whether the file has been marked
                                       for deleteion by a previous remove
                                       system call. */
  char name[NAME_MAX + 1];          /* Name of the file. */
};

--- In allocate_fd --:
  static int fd_current = 2;        /* Keeps track of the next unique fd
                                       number to be given out. */

------------ thread.h -----------------

/* States in a process' life cycle. 
   (Owned by userprog/process.c) */
enum process_status
  {
    PROCESS_STARTING,   /* Process has not yet started. */
    PROCESS_STARTED,    /* Process has successfully loaded. */
    PROCESS_FAILED,     /* Process failed to load. */
    PROCESS_DONE,       /* Process has terminated. */
    PROCESS_ORPHANED    /* The process' parent has died, so the process
                           must no longer try to report status changes
                           to the parent. */
  }

/* Process identifier type.
   Note that the pid of a user process is the same as
   the tid of the thread running the process. */
typedef int pid_t;

/* Owned by userprog/process.c. */
struct child_status
  {
    struct list_elem elem;              /* List element for adding this struct
                                           to a process' list of children. */
    pid_t pid;                          /* pid of the child process. */
    enum process_status status;         /* process status of the child. */
    int exit_code;                      /* Exit code of process, only valid
                                           if the process has already
                                           run and terminated. */
  };

--- In struct thread --
    struct file *executable;            /* Loaded executable for this user
                                           process. */
    struct thread *parent;              /* Parent thread. */
    struct child_status *my_status;     /* Pointer to this thread's child_status
                                           block in the parent thread. */                                        
    struct list children;               /* Child processes of this thread. */
    struct lock child_changed_lock;     /* Lock associated with the condition
                                           variable below. */
    struct condition child_changed;     /* Condition variable for signalling
                                           that one of this thread's children
                                           has changed status. */
    struct list open_files;             /* Files currently opened by this
                                           thread's process. */

------------ process.c -----------------

static struct lock process_death_lock;  /* Must be acquired by a process that
                                           wishes to exit. */

>> B2: Describe how file descriptors are associated with open files.
>> Are file descriptors unique within the entire OS or just within a
>> single process?

File descriptors are associated with open files via a hash table that
is static to syscall.c. The hash table entries contain FD numbers,
information about the corresponding file, as well as the process to
which the file belongs.

File descriptors are unique within the entire OS, since the hash table
described above is static to syscall.c. FD numbers are allocated by
a static function in syscall.c that contains a static variable indicating
the next FD number to give out.

---- ALGORITHMS ----

>> B3: Describe your code for reading and writing user data from the
>> kernel.

We chose to make the reading/writing of user data in the kernel as
conceptually simple as possible. First, we made a function
translate_vaddr, which attempts to translate a virtual address into
a physical address, returning NULL if the virtual address isn't in
user space or isn't mapped to a physical address. For a single-byte
element such as the system call number, this suffices to ensure that
we can read the user data (since we have validated that byte).

For multi-byte buffers, we simply call translate_vaddr on the first
and last bytes of the buffer, as well as every intermediate page that
the buffer spans. We do so in order to ensure that the entire buffer
is mapped into physical memory, not just the first and last pages of
it.

For null-terminated strings, we march along the string, validating
each address then reading the byte at the address, until we find
the null-terminator, find unmapped memory, or exceed a length limit
that is passed into the validation function.

>> B4: Suppose a system call causes a full page (4,096 bytes) of data
>> to be copied from user space into the kernel.  What is the least
>> and the greatest possible number of inspections of the page table
>> (e.g. calls to pagedir_get_page()) that might result?  What about
>> for a system call that only copies 2 bytes of data?  Is there room
>> for improvement in these numbers, and how much?

1 inspection will result from translating esp.
Between 0 and 3 inspections will result from validating 0 to 3 arguments
(each argument is treated as a 4-byte buffer, so both the beginning and
end of the argument is checked).
Finally, 2 inspections occur to validate the 4,096 byte buffer (assuming
that this is a void* buffer as in read/write, not a const char* string),
since we must validate both the first and last byte of the buffer (but
doing so suffices, since the buffer spans at most two pages).

Hence, we will perform between 3 inspections (if the buffer is somehow
used in a theoretical system call that needs no arguments) and 6
inspections (if the buffer is part of a 3-argument system call like
read or write).

The exact same numbers apply for a system call that copies 2 bytes of
data. The inspections required for esp and arguments don't change, and
the buffer check will still validate both the first and last byte of the
buffer, since 2 bytes could potentially span 2 pages.

There is very little room for improvement in these numbers - for fixed-size
buffers, we are performing the absolute minimum validation necessary, while
still ensuring complete kernel safety. Perhaps if we were to do some clever
address manipulation, we could forego the checks of the arguments if we can
clearly see that they do not lie on a page boundary. However, this kind of
micro-optimization seems more dangerous than beneficial. Of course, if we
had used the page-faulting approach, we would not require these inspections
at all.

Note, however, that these numbers change dramatically if this "data" is
string (null-terminated) data. In this case, the buffer check would require
a number of calls to pagedir_get_page equal to the length of the string.
Since the question did not specify, we are assuming that it refers to
fixed-size data.

>> B5: Briefly describe your implementation of the "wait" system call
>> and how it interacts with process termination.

Our "wait" implementation hinges on the addition of a list to the thread
structure that keeps track of "child status" blocks. For every child
process that a parent process creates, it also creates a new element in
its list of children that contains information about the child,
including pid, exit code, and running status. The child also receives a
pointer (again, added in the thread struct) to its corresponding status
block. That is, every child process has a pointer to an element in its
parent's list of child statuses.

Now, when a child changes status, it notifies its parent simply by
acquiring a lock associated with the parent's child status list, and then
changing its status block to reflect its new status. This includes failure
to load executable as well as exit code information when the process
terminates. The process also signals a condition variable in the parent.

Then, when a parent wishes to "wait" on one of its children, it simply
searches for the pid of the child in its child status list. If it is able
to find the status block, then it can tell whether the child is dead or
running. If the child is dead, it returns the exit code and removes that
child's block from the list. If the child is still alive, the parent
waits on the same condition variable inside of itself that the child will
signal when it changes status. In this way, the parent can wait on its
children to change status without having to busy wait.

Note that, when parents die before their children, the children are changed
to "orphaned" status, so that they know not to try to access their parent.

>> B6: Any access to user program memory at a user-specified address
>> can fail due to a bad pointer value.  Such accesses must cause the
>> process to be terminated.  System calls are fraught with such
>> accesses, e.g. a "write" system call requires reading the system
>> call number from the user stack, then each of the call's three
>> arguments, then an arbitrary amount of user memory, and any of
>> these can fail at any point.  This poses a design and
>> error-handling problem: how do you best avoid obscuring the primary
>> function of code in a morass of error-handling?  Furthermore, when
>> an error is detected, how do you ensure that all temporarily
>> allocated resources (locks, buffers, etc.) are freed?  In a few
>> paragraphs, describe the strategy or strategies you adopted for
>> managing these issues.  Give an example.

Since we chose to go with the pre-validation strategy, rather than
letting the page-fault mechanism protect us from bad memory access,
our code is relatively un-obscured by such error-handling.

Moreover, we implemented syscall_handler in such a way that virtually
all of the redundant error-checking is handled by this function, rather
than the individual system call functions. By the time a system call is
dispatched to the appropriate sub-handler (syscall_exit, syscall_write,
etc), all arguments have already been verified. We achieve this by using
the static array syscall_arg_count, as detailed above.

From this point on, the only checks required are string/buffer checks.
The system call functions can perform these *immediately* upon receiving
the request, which means resource freeing is easy: just don't acquire
any resources until all necessary buffers have been verified! This makes
it quite simple, conceptually, to design system calls and handle errors,
since we have eliminated the possibility of "failing at any point."

For example, observe our code for syscall_read:

syscall_read (int fd, void *buffer, unsigned size)
{
  char *cbuffer = (char*)validate_buffer (buffer, size);
  if (cbuffer == NULL)
    syscall_exit (-1);

  if (fd == STDIN_FILENO)
    {
      unsigned i;
      for (i = 0; i < size; ++i)
        *(cbuffer++) = input_getc ();
      return size;
    }
  else
    {
      lock_filesys ();
      struct file *handle = filesys_get_file (fd);
      if (handle == NULL)
        {
          unlock_filesys ();
          return -1;
        }
      off_t bytes_read = file_read (handle, buffer, size);
      unlock_filesys ();
      return bytes_read;
    }
}

Note that only two error checks occur in this (relatively complex) function:
first, the output buffer is validated. If this validation fails, then we can
immediately kill the process (note that we have NOT acquired any resources,
and that syscall_exit will take care of all the usual per-process resources).
Then, the only other check we must make is that the fd maps to a valid file
(if it is not STDIN_FILENO). If we find that the fd is invalid, all we must
do is release the filesystem lock and report an error.

By having syscall_handler automatically perform argument validation, as well
as by checking buffers for validity *before* executing the function, we are
able to avoid loads of error-handling code. This implementation of the read
syscall is easy to understand and quite transparent.

---- SYNCHRONIZATION ----

>> B7: The "exec" system call returns -1 if loading the new executable
>> fails, so it cannot return before the new executable has completed
>> loading.  How does your code ensure this?  How is the load
>> success/failure status passed back to the thread that calls "exec"?

We modified process_execute to wait until it knows whether the process
has loaded or failed to load, then process_execute simply passes this
knowledge back to exec.

To do so, we re-used the child status blocks described earlier. When a
child process fails to load its executable, it sets its status block
to "failed" and signals the parent process. Similarly, if the process
succeeds at loading, it sets its status to "started" and signals the
parent process. Thus, a parent process must simply wait on its internal
condition variable and, when signalled, check the status of the child it
just created. It will continue to do so until it detects that the child
has either started or failed, at which point it will return the process'
tid (if successful), or TID_ERROR if unsuccessful. Again, exec simply
wraps this functionality.

We saw no reason for the system call exec and process_exec to operate
in different manners, hence our implementation inside of process_exec.

>> B8: Consider parent process P with child process C.  How do you
>> ensure proper synchronization and avoid race conditions when P
>> calls wait(C) before C exits?  After C exits?  How do you ensure
>> that all resources are freed in each case?  How about when P
>> terminates without waiting, before C exits?  After C exits?  Are
>> there any special cases?

A.
  If P calls wait(C) before C exits, then P will acquire its internal
  child_changed_lock, and will wait on the condition variable
  P->child_changed. When C exits, it will acquire the same lock in P,
  modify the corresponding child status block, and signal P->child_changed.
  P then wakes up and checks to see if the child that it was waiting on
  has finished. Since both P and C protect their access to P with a lock
  inside P, we avoid race conditions.

B.
  If P calls wait(C) after C exits, then C has already updated its
  status block within P (again, this operation would have been
  synchronized by the aforementioned lock). All P must do is acquire
  P->child_changed_lock and check its status block that corresponds
  to C. This is synchronized with the same locking mechanism as in (A).
  
C.
  In either of the cases (A) or (B), since the parent terminates last,
  it is responsible for freeing the child status blocks of all children.
  Since the parent keeps track of *all* children that exist or have
  existed and have not yet been waited on, it knows exactly which memory
  must be freed. Thus, when P exits, it cleans up all of the memory
  allocated for child processes. Note that waiting on a child process
  causes the child status block to be freed as soon as the wait operation
  is complete. Either way, all status blocks are freed.
  
D.
  If P terminates without waiting, then it frees the status blocks of
  any children that have already exited. However, since C has not
  exited, P marks C's status block with the status "PROCESS_ORPHANED",
  which lets C know that it no longer has a parent. Then, when C exits,
  it will see that its status is orphaned, which indicates that it
  should *not* try to acquire the child_changed lock or notify P of
  a status change. It also recognizes that it needs to free up its own
  status block, since P will not do so. Thus, C exits cleanly and frees
  up its own memory.
  
E.
  As mentioned in (D), when P exits, it cleans up the status blocks of
  children that have exited, including C. So if P terminates without
  waiting after C exits, then P will free up the memory allocated for C's
  status block.

F.
  The worst-case-scenario (and rather special case) that we could think
  of was "what if P and C attempt to exit at the same time, and they
  interleave while exitting"? This poses a serious problem, as using
  P's lock to synchronize won't work, because doing so might leave C
  waiting on a lock that has been destroyed. To solve this race, we
  chose to create a global lock called process_death_lock that must be
  acquired during the death of a process. This protects us from P and C
  interleaving while dying, and ensures that one of the aforementioned
  (good/solved) cases will occur rather than the simultaneous death case.
  Since the lock only affects dying processes, it does not pose a
  significant threat to performance.

---- RATIONALE ----

>> B9: Why did you choose to implement access to user memory from the
>> kernel in the way that you did?

Our design for user memory access is simple and concise. This allows
for great readability and strong security. We chose to validate user
memory access rather than use the page-fault mechanism because of ease
with which it allows to write system call functions. For many of our
functions, we need only validate the user memory once, then proceed
with acquiring resources/carrying out the system call. In this sense,
we isolate the steps of validating the user memory and performing the
memory operation. If we had chosen to use the faulting mechanism, this
isolation would not be possible.

We took extra care in making our validation methods for strings and
buffers strong, so that the Kernel is protected from malicious users.

>> B10: What advantages or disadvantages can you see to your design
>> for file descriptors?

The advantage of our design lies primarily in the lack of bulky per-
process data for file descriptors. Each process keeps track of a
simple linked list of FDs, but the bulk of the data is stored
statically in syscall.c. This is a good thing when the system has
many processes, since thread structures are still quite lightweight.
The fact that FDs are unique accross all processes also means that
the mapping from FD to file* is conceptually simple and easy-to-
implement.

On the other hand, since we use global data to keep track of the fds,
the system may incur some latency if many process have lots of open
fds. In this case, the global fd hash table will become large and
lookup times will increase. However, file access already requires a
coarse lock, since the filesystem is not thread-safe, so indexing
into a global structure shouldn't be that expensive in comparison to
the (necessary) step of acquiring a global lock for each file op.

>> B11: The default tid_t to pid_t mapping is the identity mapping.
>> If you changed it, what advantages are there to your approach?

We did not change this mapping. We felt that the simplicity of the
mapping was a big win, and could see no advantages in straying from
it.

      	     SURVEY QUESTIONS
             ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

It was very unclear to us what the following means;
"You should implement the standard Unix semantics for files. That is,
when a file is removed any process which has a file descriptor for that
file may continue to use that descriptor. [...] "

It is very unclear how much of this already exists. We did some digging
and found that the filesystem inodes already support a reference-counting
mechanism, but, annoyingly, that the directory layer does not make use
of this mechanism (why!?!?). Given that we were advised not to touch
the file system code, it seemed that the best choice was to write another
reference-counting mechanism at the syscall layer. We're still unsure if
this was the intent of the assignment, as it seems silly to write another
reference-counter when one already exists at a lower level. But we did it
anyway to ensure compliance with the (rather vague) directions.

Another area of poor clarity for us was memory access in syscall.c. We
now understand that Pintos runs in mapped mode even when in the Kernel,
but that didn't seem clear to us after reading the directions several
times.

Finally, problem B4 is confusing and ambiguous. What kind of data is it?
Why/where is it being read into the kernel? Etc. This question really
needs to be cleaned up for next time!

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?
